---
title: "Open science"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
author: Marcel Miché
bibliography: osRefs.bib
editor: visual

execute: 
  warning: false
  message: false
---

## Checkliste(n)

Checklisten sind gut, falls man sicher im Umgang damit ist. Heisst: Wenn man das Steuer in der Hand behält (was leider keine Selbstverständlichkeit ist), können Checklisten sehr positiv sein. Hauptsächlich dafür, dass man nichts Wichtiges vergisst. Hierfür muss man aber eben beurteilen können (und wollen!), welche Punkte der Checkliste aus welchen Gründen für das eigene Projekt momentan sehr wichtig sind, weniger wichtig sind usw. Dies ist die wichtigste Aufgabe überhaupt, die keine Checkliste der Welt abnehmen kann.

## Beurteilung

Hört sich vielleicht zu idealistisch an, aber was soll's: Eure Beurteilung eurer Arbeit sollte für euch mindestens ebenso wichtig sein wie die Beurteilung, die andere über eure Arbeit abgeben. Es muss nicht zwingend zu einem Konflikt kommen, aber man muss es wohl manchmal austesten, anstatt sich stillschweigend an Vorgaben zu halten, gegen die man gute Gründe zur Ablehnung sieht, d.h. eine Alternative zu bevorzugen. Das gilt nicht nur hinsichtlich der Masterarbeit, sondern auch später hinsichtlich Publikationen. Zum Beispiel Reviewer/innen gegebenenfalls zu verdeutlichen, warum man statistical significance testing **nicht** durchgeführt, sondern eine bessere Alternative bevorzugt hat [@savitz2024responding], die man selbstverständlich zuvor verstanden haben und sie dem/der Leser/in verständlich erklärt haben sollte. Es wird dabei nicht ausbleiben, dass man erst dann (nachdem mehrere Jahre vergangen sind) zu merken beginnt, wie kontraproduktiv das akademische "System" häufig funktioniert, d.h. entgegen der Aussendarstellung (Stichworte: Exzellente Forschung, exzellente Lehre, fortschrittliche Entwicklung) scheint es bessere Alternativen ziemlich rigoros und wirksam auszubremsen. Der mögliche Grund dafür, der sich mir als erstes aufdrängt, ist simple Vermeidung. Vermeidung des Lostretens einer möglichen Lawine von Peinlichkeiten, denn fängt man erst einmal damit an, x als Fehler einzugestehen, dann kommt das Thema Folgefehler und Folgefehler von Folgefehlern ins Rollen. Der grossen Mehrheit etablierter Forscher/innen scheint es näher zu liegen, lieber so weiter zu machen wie bisher: Darauf zu hoffen und zu vertrauen, dass alles im Grossen und Ganzen im grünen Bereich ist; und in dieser Hoffnung den Staffelstab an euch, die nächste Generation, weiterzugeben.

## Anhang bzw. Zusatzmaterial

Falls jemand von euch zukünftig eine oder mehrere wissenschaftliche Arbeit(en) publizieren möchte, wird sich automatisch die open science (also: Transparenz) Frage stellen, nämlich: Wie viel und was genau darf bzw. soll bzw. muss es sein? Stichwort Burnout. Schon wieder steht, wie beim Punkt "Checkliste(n)", die Kompetenz und somit die eigenständige Beurteilung im Raum. Ganz besonders zu Beginn eines Doktorates sind sehr viele Personen unglaublich motiviert. Jedoch kann dies auch nach hinten losgehen [@benlidayi2025paradox]. Damit soll gesagt sein, dass der Leitspruch "Weniger ist mehr" nie vergessen werden sollte. Auf "Transparenz" bezogen heisst das: "So wenig wie möglich, so viel wie nötig." Die Gefahr besteht, dass man es mit Transparenz auch übertreiben kann, zum eigenen Nachteil und zum Nachteil des/der Leser/in eurer Publikation(en), wenn nämlich der roten Faden verloren geht.

### Beispiel

Bei unserer früheren Publikation [@miche2024evaluating] ist das Zusatzmaterial ziemlich ausführlich, z.B. Sektion 7 von "Additional file 2". Es gibt sogar auch noch ein "Additional file 1", das von den Reviewer/innen angestossen worden war. Bei unserem derzeitigen Manuskript (Vorhersagemodel zum Outcome Alcohol Use Disorder) habe ich absichtlich das "Weniger ist mehr" berücksichtigt. Zum grossen Teil deshalb, weil ich nach Publikationen zum Thema "Zusatzmaterial" (Supplementary material) gesucht hatte [z.B. @pop2015use]. Dort steht u.a., dass "Zusatzmaterial" eigentlich nur zusätzliche Tabellen und Graphiken enthalten sollte, nicht aber eigene "Kapitel" bzw. generell nicht viel Text. Und zwar deshalb nicht, weil es sehr wahrscheinlich ist, dass dieser teils umfangreiche Zusatz von den Reviewer/innen entweder gar nicht oder nur oberflächlich begutachtet wird. Jedoch gilt auch hier (schon) wieder: Man muss selbst im Einzelfall beurteilen, was aus welchen Gründen wichtig ist und welchen sinnvollen Umfang es haben soll [z.B., @meehan2022clinical]. Es ist eine gute Übung, sich einmal die ein oder andere Publikation und dessen Zusatzmaterial anzusehen und zu beurteilen, ob statt kompetenter Transparenz (so wenig wie möglich, so viel wie nötig) der rote Faden verloren gegangen ist.

## Auf den Punkt gebracht

Um es auf den Punkt zu bringen: Es besteht ein deutlicher Konflikt zwischen der Forderung (heute scheinbar noch stärker als früher) mindestens eine Publikation pro Jahr, wenn möglich zwei oder sogar drei (oder vier, ...) als Erstautor/in zu produzieren, und dem öffentlichen sowie persönlichen Anspruch zu genügen, eine qualitativ hochwertige, wissenschaftlich relevante Arbeit anzufertigen. Mir drängt sich jedenfalls die Frage auf, weshalb scheinbar unbemerkt Psycholog/inn/en die Forderung möglichst vieler Publikationen (als Erstautor/in) tatsächlich erfüllen, während parallel dazu Methodolog/inn/en dieselbe Forderung erfüllen, wobei jedoch viele jener Publikationen die unzähligen Schwächen und Miss- oder sogar Fehlverständnisse psychologischer Publikationen identifizieren, diskutieren und in Empfehlungen ummünzen [@sue1999science; @hamann2022getting; @wulff2023common; @schubert2025improving]. Sei es bezogen darauf [wie bzw. was Psycholog/inn/en zu "messen" versuchen](https://metaresearch.nl/blog/2025/1/13/the-measurement-crisis-a-hidden-flaw-in-psychology) oder die unglaubliche Tatsache, dass seit Jahrzehnten wahnsinnig vielen Forscher/inne/n klar zu sein scheint, dass "etwas" im massenhaft verwendeten p-Wert ganz und gar nicht stimmt, und trotz dieses breit vorhandenen Wissens **keine** Korrektur stattfindet [@goodman1993p; @krueger2001null; @gigerenzer2004mindless; @emmert2024trends], weder in den Publikationen, noch in der Lehre, von verschwindend wenigen Ausnahmen abgesehen. Wie viel deutlicher kann entweder Inkompetenz oder zumindest Gleichgültigkeit öffentlich demonstriert werden?! Am unglaublichsten ist aber die Tatsache, dass es niemanden wirklich zu interessieren scheint (von verschwindend wenigen Ausnahmen abgesehen), denn es geht ja (zum grossen oder grössten Teil) weiter wie bisher. Was unmöglich wäre, wenn Forschungsgelder dafür nicht weiterhin bewilligt werden würden. Seltsamer Kreislauf, sehr seltsam.

## Fazit

You do the math. Und wenn möglich: Macht es besser. Ein möglicher Anfang: Lest die Hausarbeit (Konfidenzintervall interpretieren.pdf) von eurem Kommilitonen Adam, die ich leicht korrigiert und ergänzt habe. Nach dem Lesen sollte euch bestenfalls vollkommen klar sein (in alle Ewigkeit), wie das 95% Konfidenzinterval zu interpretieren ist **und** warum es niemals etwas mit 95%igem Vertrauen zu tun hatte bzw. je haben wird.

P.S.: Wen es interessieren sollte, siehe R-Skript InterpretConfidenceIntervals mit einer kleinen Simulation, sowie erklärenden Kommentaren.

## Nachtrag 1

Bei weiterer Literaturrecherche bin ich noch auf zwei aktuelle Publikationen gestossen [@lindsay2025null; @hosni2025follows], die ich euch zukommen lassen will. Grund: Beide ermöglichen sehr wichtige und umfangreiche Einsichten dazu, wie es soweit kommen konnte, d.h. wie "er" (der p-Wert) soweit kommen konnte. Ein vermuteter Grund: "It does not matter if it does not mean what people think it means; it becomes valuable because of what it buys within the academic community regarding publication, funding, promotion, and the pretense of scientific respectability." [Seite 3, in @lindsay2025null]. Leider muss hier betont werden, dass mit "people" nicht Laien gemeint sind, sondern eine RIESIGE Menge erfolgreicher "Wissenschaftler/innen", die eine ebenfalls RIESIGE Menge Studierende zu "Wissenschaftler/innen" ausgebildet haben und weiter ausbilden. Wie positiv hört sich im Kontrast dazu der erste Satz an, mit dem eine andere aktuelle Publikation [@braitman2025graduate] beginnt: "Quantitative methodology is often part of the core curriculum for training in psychology and is required of graduate students across all subdisciplines; as such, the depth and breadth of course content is a universal issue among psychology training programs \[...\]." Natürlich ist mir klar, dass man einen Artikel nicht beginnen kann mit "WTF is going on?!" So etwas ginge wohl nur in der Fantasie, aber immerhin, besser als nirgendwo. Zur Publikation von @lindsay2025null, die immerhin bereits 10 Mal zitiert wurde, ist zu erwähnen, dass die Forderung "to abandon the NHST *paradigm*" sehr unrealistisch ist. Vermutlich meint der Autor einfach das Offensichtliche, nämlich dass diejenigen, die NHST falsch anwenden und es entsprechend genauso lehren, damit aufhören sollen (weil falsch!). Wünschen wir dem Autor, dass wir alle ihn richtig verstehen und seiner impliziten Bitte nachkommen werden. Während @trafimow2025going eine Alternative zu NHST beschreibt, behauptet @falta2025null, dass die Wurzel des Problems woanders liegt, also nicht beim NHST *Paradigma*. Viel Spass und behaltet die Orientierung!

## Nachtrag 2

Mehr oder weniger zufällig(?) bin ich kürzlich noch auf eine Publikation gestossen [@uher2025statistics], wodurch ich zudem auf diese Publikation [@uher2025psychology] aufmerksam wurde. Ähnlich wie im Abschnitt "Nachtrag 1", d.h. in den dort zitierten Papern, liest man Beschreibungen von Problemen, die im wissenschaftlichen Arbeitskontext grösser nicht sein könnten! Beispiel: Es wird vorgeschlagen, das letzte Wort in "Questionable Research Practice" durch "Fundamentals" zu ersetzen, um die Wurzel des Problems beim richtigen Namen zu nennen. Wenn das stimmen sollte, d.h. wenn das Fundament der akademischen Psychologie schimmelt, nun, was dann? Beide Publikationen sind recht lang (30 bzw. 32 Seiten, Referenzen nicht eingerechnet), was bereits die Wahrscheinlichkeit stark verringert, dass es von den Psycholog/inn/en gelesen werden wird, deren Publikationen sowie deren Lehrinhalte (besser gesagt, das teilweise oder völlige Verschweigen wichtiger Lehrinhalte) die Hauptverursacher waren, sind und bleiben werden, dass das Fundament schimmelt. Vorausgesetzt, dass es wirklich schimmelt. Manche Leute behaupten, dass alles in Butter ist, exzellent. Wenn das wirklich stimmen sollte, ...

## Nachtrag 3

Eine eigenständige Erwähnung verdient die Publikation von @jamieson2023reflexivity. Der Inhalt stellt die grösstmögliche Herausforderung dar, der wohl nur die wenigsten Forscher/innen wirklich gerecht werden, nämlich das Maximum an Transparenz und Ehrlichkeit öffentlich zu machen. Das heisst, sogar seine inidividuell-persönlichen Befangenheiten, Vorurteile usw. zu ergründen und sie dem/der Leser/in mitzuteilen. Vermutlich kann so etwas mit dem Artikel von @jamieson2020moving verknüpft werden kann. Eine Verknüpfung, die mir ins Auge fiel, möchte ich hier noch nennen: Die Einführung in @jamieson2020moving (S. 273) endet mit "\[...\] we are skeptical that psychology will escape the replication crisis by improvements in research practice alone.", was sich sehr ähnlich liest wie oben in Nachtrag 2 "Questionable Research Fundamentals" (anstatt "Questionable Research Practice"). Also der Hinweis, dass das eigentliche Problem, das sich euch als der open science Generation stellt, nicht einfach nur eine Frage der "practice" ist. Mit dem Inhalt von Nachtrag 1 ist es verbunden, weil dort die Hauptkritik lautet: NHST kann man entweder kompetent anwenden oder rein oberflächlich (mechanisch). Oberflächliche Anwendung war in den letzten 60-80 Jahren (und auch heute) der Regelfall (= inkompetente Anwendung).

**Somit, finales Fazit**: Egal was es ist, das man anwendet, z.B. NHST, solange man nicht **fundamental** Bescheid weiss (= sich selbst ehrlich gegenüber ist, ob man es wirklich verstanden hat), wird man zur oberflächlichen Anwendung neigen. Das geht uns heute nicht anders als den Generationen vor uns. Die Generationen vor uns haben sich grösstenteils für die oberfläche Anwendung entschieden. Genau deshalb sitzen wir heute so in der Tinte. Wie den Generationen vor uns, stellt sich also auch uns die Frage, was wir heute in die Tat umsetzen wollen (und weshalb), damit die nächste(n) Generation(en) nicht weiterhin in der Tinte sitzt/sitzen. Um solch eine Art von Motivation geht es meiner Meinung nach in @jamieson2023reflexivity, nämlich sich selbst wiederholt **fundamental** auf den Zahn zu fühlen, anstatt mit Oberflächlichkeiten wie "Baysianisch" oder "Frequentistisch" wertvolle Lebenszeit zu verschwenden.
